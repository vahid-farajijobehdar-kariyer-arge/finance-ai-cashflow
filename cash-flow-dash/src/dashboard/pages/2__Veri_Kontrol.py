"""
ğŸ” Veri KontrolÃ¼ - Kariyer.net Finans

Dosya bazÄ±nda veri kalitesi kontrolÃ¼, komisyon doÄŸrulama ve tutarlÄ±lÄ±k analizi.

Â© 2026 Kariyer.net Finans Ekibi
"""

import sys
from pathlib import Path
from datetime import datetime

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# Add project root to path for imports
PROJECT_ROOT = Path(__file__).parent.parent.parent.resolve()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from ingestion.reader import BankFileReader
from processing.commission_control import add_commission_control, get_control_summary

# Import auth module
sys.path.insert(0, str(Path(__file__).parent.parent))
from auth import check_password

# Data paths
RAW_PATH = PROJECT_ROOT.parent / "data" / "raw"


@st.cache_data(ttl=60)
def load_all_files_with_metadata():
    """Load all files with per-file metadata for validation."""
    if not RAW_PATH.exists():
        return None, []
    
    reader = BankFileReader()
    
    # Hem kÃ¶k dizindeki hem de alt klasÃ¶rlerdeki dosyalarÄ± tara
    # Alt klasÃ¶r yapÄ±sÄ±: BANKA/YYYY-MM/dosya.xlsx
    files = []
    
    # KÃ¶k dizindeki dosyalar
    for f in RAW_PATH.glob("*"):
        if f.is_file() and not f.name.startswith(".") and f.suffix.lower() in [".csv", ".xlsx", ".xls"]:
            files.append(f)
    
    # Alt klasÃ¶rlerdeki dosyalar (BANKA/YYYY-MM/dosya.xlsx)
    for bank_dir in RAW_PATH.iterdir():
        if bank_dir.is_dir() and not bank_dir.name.startswith("."):
            for month_dir in bank_dir.iterdir():
                if month_dir.is_dir():
                    for f in month_dir.glob("*"):
                        if f.is_file() and f.suffix.lower() in [".csv", ".xlsx", ".xls"]:
                            files.append(f)
    
    if not files:
        return None, []
    
    all_data = []
    file_stats = []
    
    for file_path in files:
        try:
            df = reader.read_file(file_path)
            df["source_file"] = file_path.name
            
            # Get file stats
            stats = {
                "dosya": file_path.name,
                "satir_sayisi": len(df),
                "boyut_kb": file_path.stat().st_size / 1024,
                "degistirilme": datetime.fromtimestamp(file_path.stat().st_mtime),
                "banka": df["bank_name"].iloc[0] if "bank_name" in df.columns and len(df) > 0 else "Bilinmiyor",
            }
            
            # Check for common issues
            issues = []
            
            # Check for empty columns
            empty_cols = df.columns[df.isna().all()].tolist()
            if empty_cols:
                issues.append(f"BoÅŸ sÃ¼tunlar: {', '.join(empty_cols[:3])}")
            
            # Check for missing critical columns
            required_cols = ["gross_amount", "transaction_date", "bank_name"]
            missing_cols = [c for c in required_cols if c not in df.columns]
            if missing_cols:
                issues.append(f"Eksik sÃ¼tunlar: {', '.join(missing_cols)}")
            
            # Check for null values in critical columns
            if "gross_amount" in df.columns:
                null_amount = df["gross_amount"].isna().sum()
                if null_amount > 0:
                    issues.append(f"Tutar boÅŸ: {null_amount} satÄ±r")
            
            if "transaction_date" in df.columns:
                null_date = df["transaction_date"].isna().sum()
                if null_date > 0:
                    issues.append(f"Tarih boÅŸ: {null_date} satÄ±r")
            
            # Check for duplicate transactions
            if "gross_amount" in df.columns and "transaction_date" in df.columns:
                potential_dups = df.duplicated(subset=["gross_amount", "transaction_date"], keep=False).sum()
                if potential_dups > 10:
                    issues.append(f"Potansiyel tekrar: {potential_dups} satÄ±r")
            
            # Check date range
            if "transaction_date" in df.columns:
                dates = pd.to_datetime(df["transaction_date"], errors="coerce")
                valid_dates = dates.dropna()
                if len(valid_dates) > 0:
                    stats["min_tarih"] = valid_dates.min()
                    stats["max_tarih"] = valid_dates.max()
                    
                    # Check for future dates
                    future = (valid_dates > datetime.now()).sum()
                    if future > 0:
                        issues.append(f"Gelecek tarih: {future} satÄ±r")
            
            # Calculate totals
            if "gross_amount" in df.columns:
                stats["toplam_tutar"] = df["gross_amount"].sum()
            if "commission_amount" in df.columns:
                stats["toplam_komisyon"] = df["commission_amount"].sum()
            if "net_amount" in df.columns:
                stats["toplam_net"] = df["net_amount"].sum()
            
            stats["sorunlar"] = issues
            stats["sorun_sayisi"] = len(issues)
            stats["durum"] = "âœ… Temiz" if len(issues) == 0 else f"âš ï¸ {len(issues)} Sorun"
            
            file_stats.append(stats)
            all_data.append(df)
            
        except Exception as e:
            file_stats.append({
                "dosya": file_path.name,
                "satir_sayisi": 0,
                "boyut_kb": file_path.stat().st_size / 1024,
                "degistirilme": datetime.fromtimestamp(file_path.stat().st_mtime),
                "banka": "Hata",
                "sorunlar": [f"Okuma hatasÄ±: {str(e)}"],
                "sorun_sayisi": 1,
                "durum": "âŒ Hata"
            })
    
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        return combined_df, file_stats
    
    return None, file_stats


def display_file_overview(file_stats: list):
    """Display overview of all loaded files."""
    st.subheader("ğŸ“ Dosya Durumu")
    
    if not file_stats:
        st.warning("HiÃ§ dosya bulunamadÄ±. Ã–nce dosya yÃ¼kleyin.")
        return
    
    # Summary metrics
    total_files = len(file_stats)
    clean_files = sum(1 for f in file_stats if f.get("sorun_sayisi", 0) == 0)
    problem_files = total_files - clean_files
    total_rows = sum(f.get("satir_sayisi", 0) for f in file_stats)
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Toplam Dosya", total_files)
    col2.metric("Temiz Dosya", clean_files, delta=f"{clean_files/total_files*100:.0f}%")
    col3.metric("Sorunlu Dosya", problem_files, delta=f"-{problem_files}" if problem_files > 0 else None, delta_color="inverse")
    col4.metric("Toplam SatÄ±r", f"{total_rows:,}")
    
    st.markdown("---")
    
    # File details table
    st.markdown("### ğŸ“‹ Dosya DetaylarÄ±")
    
    df_stats = pd.DataFrame(file_stats)
    
    # Format for display
    display_cols = ["dosya", "banka", "satir_sayisi", "boyut_kb", "durum"]
    if "min_tarih" in df_stats.columns:
        display_cols.insert(3, "min_tarih")
        display_cols.insert(4, "max_tarih")
    
    available_cols = [c for c in display_cols if c in df_stats.columns]
    
    st.dataframe(
        df_stats[available_cols].style.format({
            "boyut_kb": "{:.1f} KB",
            "satir_sayisi": "{:,}"
        }),
        hide_index=True,
        width="stretch"
    )
    
    # Show issues for problem files
    problem_stats = [f for f in file_stats if f.get("sorun_sayisi", 0) > 0]
    if problem_stats:
        st.markdown("### âš ï¸ Tespit Edilen Sorunlar")
        
        for stat in problem_stats:
            with st.expander(f"ğŸ“„ {stat['dosya']} - {stat['durum']}", expanded=True):
                for issue in stat.get("sorunlar", []):
                    st.warning(f"â€¢ {issue}")


def display_data_quality_checks(df: pd.DataFrame):
    """Display comprehensive data quality checks."""
    st.subheader("ğŸ”¬ Veri Kalitesi Analizi")
    
    if df is None or df.empty:
        st.warning("Veri bulunamadÄ±.")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ“Š SÃ¼tun Doluluk OranlarÄ±")
        
        # Calculate fill rates
        fill_rates = []
        for col in df.columns:
            non_null = df[col].notna().sum()
            fill_rate = non_null / len(df) * 100
            fill_rates.append({
                "SÃ¼tun": col,
                "Dolu SatÄ±r": non_null,
                "Doluluk %": fill_rate
            })
        
        fill_df = pd.DataFrame(fill_rates)
        fill_df = fill_df.sort_values("Doluluk %")
        
        # Show only columns with < 100% fill rate
        incomplete = fill_df[fill_df["Doluluk %"] < 100]
        
        if len(incomplete) > 0:
            fig = px.bar(
                incomplete.tail(15),
                x="Doluluk %",
                y="SÃ¼tun",
                orientation="h",
                title="Eksik Veri Olan SÃ¼tunlar",
                color="Doluluk %",
                color_continuous_scale="RdYlGn"
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, key="fill_rates")
        else:
            st.success("âœ… TÃ¼m sÃ¼tunlar tam dolu!")
    
    with col2:
        st.markdown("#### ğŸ“ˆ Banka BazÄ±nda Veri DaÄŸÄ±lÄ±mÄ±")
        
        if "bank_name" in df.columns:
            bank_counts = df["bank_name"].value_counts()
            
            fig = px.pie(
                values=bank_counts.values,
                names=bank_counts.index,
                title="Banka DaÄŸÄ±lÄ±mÄ±",
                hole=0.4
            )
            st.plotly_chart(fig, key="bank_dist")
        else:
            st.info("Banka bilgisi bulunamadÄ±.")
    
    st.markdown("---")
    
    # Date gap analysis
    st.markdown("#### ğŸ“… Tarih AralÄ±ÄŸÄ± Analizi")
    
    if "transaction_date" in df.columns:
        dates = pd.to_datetime(df["transaction_date"], errors="coerce")
        valid_dates = dates.dropna()
        
        if len(valid_dates) > 0:
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("En Eski Tarih", valid_dates.min().strftime("%d/%m/%Y"))
            col2.metric("En Yeni Tarih", valid_dates.max().strftime("%d/%m/%Y"))
            col3.metric("GÃ¼n AralÄ±ÄŸÄ±", f"{(valid_dates.max() - valid_dates.min()).days} gÃ¼n")
            col4.metric("GeÃ§ersiz Tarih", f"{len(dates) - len(valid_dates)} satÄ±r")
            
            # Daily transaction count
            daily_counts = valid_dates.dt.date.value_counts().sort_index()
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=daily_counts.index,
                y=daily_counts.values,
                mode="lines+markers",
                name="Ä°ÅŸlem SayÄ±sÄ±"
            ))
            fig.update_layout(
                title="GÃ¼nlÃ¼k Ä°ÅŸlem SayÄ±sÄ±",
                xaxis_title="Tarih",
                yaxis_title="Ä°ÅŸlem SayÄ±sÄ±"
            )
            st.plotly_chart(fig, key="daily_counts", width="stretch")
            
            # Check for missing days
            if len(daily_counts) > 1:
                all_days = pd.date_range(start=valid_dates.min(), end=valid_dates.max(), freq='D')
                existing_days = set(valid_dates.dt.date)
                missing_days = [d.date() for d in all_days if d.date() not in existing_days]
                
                # Filter out weekends
                missing_weekdays = [d for d in missing_days if d.weekday() < 5]
                
                if missing_weekdays:
                    st.warning(f"âš ï¸ **{len(missing_weekdays)} iÅŸ gÃ¼nÃ¼ eksik** (hafta sonlarÄ± hariÃ§)")
                    
                    with st.expander("Eksik GÃ¼nler"):
                        for d in missing_weekdays[:30]:
                            st.write(f"â€¢ {d.strftime('%d/%m/%Y (%A)')}")
                        if len(missing_weekdays) > 30:
                            st.write(f"... ve {len(missing_weekdays) - 30} gÃ¼n daha")
                else:
                    st.success("âœ… TÃ¼m iÅŸ gÃ¼nleri mevcut!")


def display_commission_validation(df: pd.DataFrame):
    """Display commission rate validation."""
    st.subheader("ğŸ’° Komisyon OranÄ± KontrolÃ¼")
    
    if df is None or df.empty:
        st.warning("Veri bulunamadÄ±.")
        return
    
    # Apply commission control
    df_controlled = add_commission_control(df.copy())
    
    if "rate_match" not in df_controlled.columns:
        st.info("Komisyon kontrol bilgisi hesaplanamadÄ±.")
        return
    
    # Summary
    total = len(df_controlled)
    matched = df_controlled["rate_match"].sum()
    mismatched = total - matched
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Toplam Ä°ÅŸlem", f"{total:,}")
    col2.metric("DoÄŸru Oran", f"{matched:,}", delta=f"{matched/total*100:.1f}%")
    col3.metric("Fark Var", f"{mismatched:,}", delta=f"-{mismatched/total*100:.1f}%" if mismatched > 0 else None, delta_color="inverse")
    
    if mismatched == 0:
        st.success("âœ… TÃ¼m komisyon oranlarÄ± beklenen deÄŸerlerle eÅŸleÅŸiyor!")
    else:
        st.warning(f"âš ï¸ {mismatched:,} iÅŸlemde komisyon farkÄ± tespit edildi.")
        
        # Show mismatched by bank
        if "bank_name" in df_controlled.columns:
            mismatch_by_bank = df_controlled[~df_controlled["rate_match"]].groupby("bank_name").size()
            
            if len(mismatch_by_bank) > 0:
                st.markdown("**Banka BazÄ±nda Fark:**")
                for bank, count in mismatch_by_bank.items():
                    st.write(f"â€¢ {bank}: {count:,} iÅŸlem")


def display_duplicate_check(df: pd.DataFrame):
    """Check for potential duplicate transactions."""
    st.subheader("ğŸ”„ Tekrar Eden Ä°ÅŸlem KontrolÃ¼")
    
    if df is None or df.empty:
        st.warning("Veri bulunamadÄ±.")
        return
    
    # Check for exact duplicates
    dup_cols = ["gross_amount", "transaction_date", "bank_name"]
    available_cols = [c for c in dup_cols if c in df.columns]
    
    if len(available_cols) >= 2:
        duplicates = df[df.duplicated(subset=available_cols, keep=False)]
        
        if len(duplicates) > 0:
            st.warning(f"âš ï¸ **{len(duplicates):,} potansiyel tekrar eden iÅŸlem** tespit edildi.")
            
            with st.expander("Tekrar Eden Ä°ÅŸlemler (ilk 50)"):
                display_cols = ["transaction_date", "bank_name", "gross_amount", "commission_amount"]
                display_cols = [c for c in display_cols if c in duplicates.columns]
                st.dataframe(duplicates[display_cols].head(50), hide_index=True)
        else:
            st.success("âœ… Tekrar eden iÅŸlem tespit edilmedi!")
    else:
        st.info("Tekrar kontrolÃ¼ iÃ§in yeterli sÃ¼tun bulunamadÄ±.")


def main():
    st.set_page_config(page_title="Veri KontrolÃ¼", page_icon="ğŸ”", layout="wide")
    
    # Require authentication
    if not check_password():
        return
    
    st.title("ğŸ” Veri KontrolÃ¼")
    st.markdown("YÃ¼klenen dosyalarÄ±n kalite kontrolÃ¼ ve tutarlÄ±lÄ±k analizi.")
    st.markdown("---")
    
    # Load data
    df, file_stats = load_all_files_with_metadata()
    
    if not file_stats:
        st.error("""
        âŒ Dosya bulunamadÄ±.
        
        Ã–nce 'ğŸ“¤ Dosya YÃ¼kle' sayfasÄ±ndan dosya yÃ¼kleyin.
        """)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“ Dosya Durumu",
        "ğŸ”¬ Veri Kalitesi",
        "ğŸ’° Komisyon KontrolÃ¼",
        "ğŸ”„ Tekrar KontrolÃ¼"
    ])
    
    with tab1:
        display_file_overview(file_stats)
    
    with tab2:
        display_data_quality_checks(df)
    
    with tab3:
        display_commission_validation(df)
    
    with tab4:
        display_duplicate_check(df)


if __name__ == "__main__":
    main()
